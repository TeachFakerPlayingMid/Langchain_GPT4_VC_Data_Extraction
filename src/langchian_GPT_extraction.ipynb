{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "DATA_PATH = Path() / \"../data\"\n",
    "#DATA_PATH = Path('/content/gdrive/My Drive/Colab Notebooks/VC_data_Cleaning_With_LLM/data')\n",
    "DATA_PATH.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "def load_data(filename, data_path=DATA_PATH,encoding='ISO-8859-1'):\n",
    "    csv_path = data_path / filename\n",
    "    return pd.read_csv(csv_path,encoding=encoding)\n",
    "\n",
    "def save_data(data, filename, data_path=DATA_PATH,encoding='ISO-8859-1'):\n",
    "    csv_path = data_path / filename\n",
    "    data.to_csv(csv_path, index=False,encoding='ISO-8859-1')\n",
    "\n",
    "PLOT_PATH = Path() / \"../plot\"\n",
    "#PLOT_PATH = Path('/content/gdrive/My Drive/Colab Notebooks/VC_data_Cleaning_With_LLM/plot')\n",
    "PLOT_PATH.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300, transparent=True):\n",
    "    path = PLOT_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution, transparent=transparent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from kor.extraction import create_extraction_chain\n",
    "from kor.nodes import Object,Text, Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def json_dump(json_object):\n",
    "    json_formatted_str = json.dumps(json_object, indent=2,ensure_ascii= False)\n",
    "    print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the openai module\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Person.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "    role: Optional[str] = Field(\n",
    "        ..., description=\"The role or title of this person. \"\n",
    "                                )\n",
    "    company: Optional[str] = Field(\n",
    "        ..., description=\"The company this person is working in.\"\n",
    "    )\n",
    "    ai_related: Optional[bool] = Field(\n",
    "        ..., description=\"Whether this person is related to AI.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Define a custom prompt to provide instructions and any additional context.\n",
    "# 1) You can add examples into the prompt template to improve extraction quality\n",
    "# 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
    "#    about the document from which the text was extracted.)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Only extract relevant information from the text. \"\n",
    "            \"If you do not know the value of an attribute asked to extract\"\n",
    "            \"return null for the attribute's value.\"\n",
    "\n",
    "            \"The list we input is a list of people's biography. Each element in the list is a person's biography text.\"\n",
    "            \"You should treat every element in the list as a separate entity.\"\n",
    "\n",
    "            \"For each person, you should consider:\"\n",
    "            \"If this person has several roles, we should only annotate one.\"\n",
    "            \"If this person is a AI company founder or co-founder, annotate him as a co-founder.\"\n",
    "            \"If this person is a researcher in AI feild, annotate this person as a researcher.\"\n",
    "            \"If you can't find any role, try to conclude the role from the context, if you still can't find any role, please annotate the role as NA.\"\n",
    "\n",
    "            \"when you extract company name, please extract the full name of the company and exclude any other punctuation mark such as @.\"\n",
    "            \"If there is no company name, please annotate the company name as NA.\"\n",
    "\n",
    "            \"If this person is related to AI, or anything about AI, please annotate the AI_related as true, otherwise annotate it as false.\"\n",
    "\n",
    "        ),\n",
    "        # Please see the how-to about improving performance with\n",
    "        # reference examples.\n",
    "        # MessagesPlaceholder('examples'),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about people.\"\"\"\n",
    "\n",
    "    # Creates a model so that we can extract multiple entities.\n",
    "    people: List[Person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Dict, List, TypedDict\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "\n",
    "class Example(TypedDict):\n",
    "    \"\"\"A representation of an example consisting of text input and expected tool calls.\n",
    "\n",
    "    For extraction, the tool calls are represented as instances of pydantic model.\n",
    "    \"\"\"\n",
    "\n",
    "    input: str  # This is the example text\n",
    "    tool_calls: List[BaseModel]  # Instances of pydantic model that should be extracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_example_to_messages(example: Example) -> List[BaseMessage]:\n",
    "    \"\"\"Convert an example into a list of messages that can be fed into an LLM.\n",
    "\n",
    "    This code is an adapter that converts our example to a list of messages\n",
    "    that can be fed into a chat model.\n",
    "\n",
    "    The list of messages per example corresponds to:\n",
    "\n",
    "    1) HumanMessage: contains the content from which content should be extracted.\n",
    "    2) AIMessage: contains the extracted information from the model\n",
    "    3) ToolMessage: contains confirmation to the model that the model requested a tool correctly.\n",
    "\n",
    "    The ToolMessage is required because some of the chat models are hyper-optimized for agents\n",
    "    rather than for an extraction use case.\n",
    "    \"\"\"\n",
    "    messages: List[BaseMessage] = [HumanMessage(content=example[\"input\"])]\n",
    "    openai_tool_calls = []\n",
    "    for tool_call in example[\"tool_calls\"]:\n",
    "        openai_tool_calls.append(\n",
    "            {\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    # The name of the function right now corresponds\n",
    "                    # to the name of the pydantic model\n",
    "                    # This is implicit in the API right now,\n",
    "                    # and will be improved over time.\n",
    "                    \"name\": tool_call.__class__.__name__,\n",
    "                    \"arguments\": tool_call.json(),\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "    messages.append(\n",
    "        AIMessage(content=\"\", additional_kwargs={\"tool_calls\": openai_tool_calls})\n",
    "    )\n",
    "    tool_outputs = example.get(\"tool_outputs\") or [\n",
    "        \"You have correctly called this tool.\"\n",
    "    ] * len(openai_tool_calls)\n",
    "    for output, tool_call in zip(tool_outputs, openai_tool_calls):\n",
    "        messages.append(ToolMessage(content=output, tool_call_id=tool_call[\"id\"]))\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    (\n",
    "        \"Research Scientist at Google DeepMind. I tweet about deep learning (research + software), music, generative models (personal account).\",\n",
    "        Person(role=\"Research Scientist\", company=\"Google DeepMind\", interest=\"deep learning, music, and generative models\", ai_related=True),\n",
    "    ),\n",
    "    (\n",
    "        \"I make videos.\\nSkill &gt; Destiny.\\nvi / vim\",\n",
    "        Person(role=None, company=None, interest=None, ai_related=False),\n",
    "    ),\n",
    "    (\n",
    "        \"ML Researcher, co-leading Superalignment @OpenAI. Optimizing for a post-AGI future where humanity flourishes.\",\n",
    "        Person(role=\"ML Researcher\", company=\"OpenAI\", interest=\"AGI\", ai_related=True),\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "messages = []\n",
    "\n",
    "for text, tool_call in examples:\n",
    "    messages.extend(\n",
    "        tool_example_to_messages({\"input\": text, \"tool_calls\": [tool_call]})\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name = 'gpt-4-turbo-preview',\n",
    "    temperature = 0,\n",
    "    openai_api_key = OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | llm.with_structured_output(\n",
    "    schema=Data,\n",
    "    method=\"function_calling\",\n",
    "    include_raw=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('twitter_combined.csv')\n",
    "# Drop NaN values from the 'bio' column\n",
    "df = df.dropna(subset=['bio'])\n",
    "\n",
    "# Combine all text in the 'bio' column into a list, considering only the first 100 texts\n",
    "documents = df['bio'].head(20).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Making medicines differently to bring better drugs faster to the patients who benefit most with ML and data at scale.',\n",
       " '#LearnWithoutLimits on Coursera. Access online courses and degrees from world-class universities and companies. Visit https://t.co/iZWWGG1ypn for support.',\n",
       " 'The leading news source for higher education. Get our newsletters: https://t.co/zfAnZfGsHc',\n",
       " \"Sharing things I'm learning through my foundation work and other interests.\",\n",
       " 'Policy research at @openai. I mostly tweet about AI, animals, and sci-fi. He/him. Views my own.',\n",
       " 'Co-Founder of OpenAI',\n",
       " 'Chief Scientist, Google DeepMind and Google Research. Co-designer/implementor of things like @TensorFlow, MapReduce, Bigtable, Spanner, Gemini .. (he/him)',\n",
       " 'VP of Research & Deep Learning Lead, Google DeepMind. Gemini co-lead.\\n\\nPast: AlphaStar, AlphaFold, AlphaCode, WaveNet, seq2seq, distillation, TF.',\n",
       " '@AnthropicAI, ONEAI OECD, co-chair @indexingai, writer @ https://t.co/3vmtHYkaTu Past: @openai, @business @theregister. Neural nets, distributed systems, weird futures',\n",
       " 'Research Scientist at Google DeepMind. I tweet about deep learning (research + software), music, generative models (personal account).',\n",
       " '@openminedorg, @GoogleDeepMind ethics team, @OxfordUni phd candidate, @UN pet lab, @GovAI_, creator of #GrokkingDeepLearning, NALU, and sense2vec',\n",
       " 'a combination of a mediocre scientist, a mediocre manager, a mediocre advisor & a mediocre PC at @nyuniversity (@CILVRatNYU) & @genentech (@PrescientDesign).',\n",
       " 'I research intelligence to understand what we are, and to harness it wisely. I lead a wonderfully creative AI team at @GoogleDeepMind who inspire me everyday.',\n",
       " 'I make videos.\\nSkill &gt; Destiny.\\nvi / vim',\n",
       " 'Professor: CMU/@acmi_lab, CTO / CSO: @AbridgeHQ, Creator: @d2l_ai & https://t.co/QQt98VNLUp, Relapsing ð\\x9f\\x8e·',\n",
       " 'Director, @StanfordAILab. Assoc. Director, @StanfordHAI. Founder, @stanfordnlp. Prof. CS & Linguistics, @Stanford. IP @aixventureshq. ð\\x9f\\x87¦ð\\x9f\\x87º Do #NLProc & #AI. ð\\x9f\\x91\\x8b',\n",
       " 'Chief scientist & Co-founder @RekaAILabs \\npast: Research Scientist @Google Brain ð\\x9f§\\xa0\\ncurrently learning to be a dad ð\\x9f\\x8d¼ð\\x9f\\x91¶',\n",
       " 'Research Scientist & Manager @GoogleDeepMind Tokyo/MTV. ex: @GoogleAI Brain, @OpenAI. (JP: @shanegJP)',\n",
       " 'ML Researcher, co-leading Superalignment @OpenAI. Optimizing for a post-AGI future where humanity flourishes.',\n",
       " 'Principal Scientist @ Google DeepMind\\nWork on Gemini ð\\x9f\\x92\\x8eâ\\x99\\x8a\\nCompression is all you need\\nLLMs (e.g. Gopher, Chinchilla, Gemini)\\nð\\x9f\\x92¼ Past: OpenAI, Quora']"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''\n",
    "  Policy research at @openai. \n",
    "  I mostly tweet about AI, animals, and sci-fi. He/him. Views my own.\n",
    "  Chief Scientist, Google DeepMind and Google Research. Co-designer/implementor of things like @TensorFlow, MapReduce, Bigtable, Spanner, Gemini .. (he/him)\n",
    "'''\n",
    "texts = ['Making medicines differently to bring better drugs faster to the patients who benefit most with ML and data at scale.',\n",
    " '#LearnWithoutLimits on Coursera. Access online courses and degrees from world-class universities and companies. Visit https://t.co/iZWWGG1ypn for support.',\n",
    " 'The leading news source for higher education. Get our newsletters: https://t.co/zfAnZfGsHc']\n",
    "\n",
    "text = documents\n",
    "\n",
    "output = runnable.invoke({\"text\": text, \"examples\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(role='NA', company='NA', ai_related=True), Person(role='NA', company='Coursera', ai_related=False), Person(role='NA', company='NA', ai_related=False), Person(role='NA', company='NA', ai_related=False), Person(role='researcher', company='OpenAI', ai_related=True), Person(role='co-founder', company='OpenAI', ai_related=True), Person(role='Chief Scientist', company='Google DeepMind', ai_related=True), Person(role='VP of Research & Deep Learning Lead', company='Google DeepMind', ai_related=True), Person(role='NA', company='AnthropicAI', ai_related=True), Person(role='Research Scientist', company='Google DeepMind', ai_related=True), Person(role='NA', company='OpenMined', ai_related=True), Person(role='NA', company='New York University', ai_related=False), Person(role='NA', company='Google DeepMind', ai_related=True), Person(role='NA', company='NA', ai_related=False), Person(role='Professor', company='Carnegie Mellon University', ai_related=True), Person(role='Director', company='Stanford AI Lab', ai_related=True), Person(role='Chief scientist & Co-founder', company='Reka AI Labs', ai_related=True), Person(role='Research Scientist & Manager', company='Google DeepMind', ai_related=True), Person(role='ML Researcher', company='OpenAI', ai_related=True), Person(role='Principal Scientist', company='Google DeepMind', ai_related=True)])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>company</th>\n",
       "      <th>ai_related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NA</td>\n",
       "      <td>Coursera</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>researcher</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>co-founder</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chief Scientist</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VP of Research &amp; Deep Learning Lead</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NA</td>\n",
       "      <td>AnthropicAI</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NA</td>\n",
       "      <td>OpenMined</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NA</td>\n",
       "      <td>New York University</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NA</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Professor</td>\n",
       "      <td>Carnegie Mellon University</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Director</td>\n",
       "      <td>Stanford AI Lab</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chief scientist &amp; Co-founder</td>\n",
       "      <td>Reka AI Labs</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Research Scientist &amp; Manager</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ML Researcher</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Principal Scientist</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   role                     company  \\\n",
       "0                                    NA                          NA   \n",
       "1                                    NA                    Coursera   \n",
       "2                                    NA                          NA   \n",
       "3                                    NA                          NA   \n",
       "4                            researcher                      OpenAI   \n",
       "5                            co-founder                      OpenAI   \n",
       "6                       Chief Scientist             Google DeepMind   \n",
       "7   VP of Research & Deep Learning Lead             Google DeepMind   \n",
       "8                                    NA                 AnthropicAI   \n",
       "9                    Research Scientist             Google DeepMind   \n",
       "10                                   NA                   OpenMined   \n",
       "11                                   NA         New York University   \n",
       "12                                   NA             Google DeepMind   \n",
       "13                                   NA                          NA   \n",
       "14                            Professor  Carnegie Mellon University   \n",
       "15                             Director             Stanford AI Lab   \n",
       "16         Chief scientist & Co-founder                Reka AI Labs   \n",
       "17         Research Scientist & Manager             Google DeepMind   \n",
       "18                        ML Researcher                      OpenAI   \n",
       "19                  Principal Scientist             Google DeepMind   \n",
       "\n",
       "    ai_related  \n",
       "0         True  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  \n",
       "5         True  \n",
       "6         True  \n",
       "7         True  \n",
       "8         True  \n",
       "9         True  \n",
       "10        True  \n",
       "11       False  \n",
       "12        True  \n",
       "13       False  \n",
       "14        True  \n",
       "15        True  \n",
       "16        True  \n",
       "17        True  \n",
       "18        True  \n",
       "19        True  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract information to a list of dictionaries\n",
    "people_data = [{\"role\": person.role, \"company\": person.company, \"ai_related\": person.ai_related} for person in output.people]\n",
    "\n",
    "# Convert to DataFrame\n",
    "bio_df = pd.DataFrame(people_data)\n",
    "\n",
    "bio_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
