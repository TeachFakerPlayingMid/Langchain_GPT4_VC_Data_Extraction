{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "DATA_PATH = Path() / \"../data\"\n",
    "#DATA_PATH = Path('/content/gdrive/My Drive/Colab Notebooks/VC_data_Cleaning_With_LLM/data')\n",
    "DATA_PATH.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "def load_data(filename, data_path=DATA_PATH,encoding='ISO-8859-1'):\n",
    "    csv_path = data_path / filename\n",
    "    return pd.read_csv(csv_path,encoding=encoding)\n",
    "\n",
    "def save_data(data, filename, data_path=DATA_PATH,encoding='ISO-8859-1'):\n",
    "    csv_path = data_path / filename\n",
    "    data.to_csv(csv_path, index=False,encoding='ISO-8859-1')\n",
    "\n",
    "def load_excel(filename, data_path=DATA_PATH):\n",
    "    csv_path = data_path / filename\n",
    "    return pd.read_excel(csv_path)\n",
    "\n",
    "PLOT_PATH = Path() / \"../plot\"\n",
    "#PLOT_PATH = Path('/content/gdrive/My Drive/Colab Notebooks/VC_data_Cleaning_With_LLM/plot')\n",
    "PLOT_PATH.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300, transparent=True):\n",
    "    path = PLOT_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution, transparent=transparent)\n",
    "\n",
    "RESULT_PATH = Path() / \"../result\"\n",
    "#PLOT_PATH = Path('/content/gdrive/My Drive/Colab Notebooks/VC_data_Cleaning_With_LLM/plot')\n",
    "RESULT_PATH.mkdir(parents=True,exist_ok=True)\n",
    "def save_result(data, filename, data_path=RESULT_PATH):\n",
    "    csv_path = data_path / filename\n",
    "    data.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "def save_excel(data, filename, data_path=RESULT_PATH):\n",
    "    csv_path = data_path / filename\n",
    "    data.to_excel(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from kor.extraction import create_extraction_chain\n",
    "from kor.nodes import Object,Text, Number\n",
    "# Import the openai module\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def json_dump(json_object):\n",
    "    json_formatted_str = json.dumps(json_object, indent=2,ensure_ascii= False)\n",
    "    print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Person.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "    role: Optional[str] = Field(\n",
    "        ..., description=\"The role or title of this person. \"\n",
    "                                )\n",
    "    company: Optional[str] = Field(\n",
    "        ..., description=\"The company this person is working in.\"\n",
    "    )\n",
    "    ai_related: Optional[bool] = Field(\n",
    "        ..., description=\"Whether this person is related to AI.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Define a custom prompt to provide instructions and any additional context.\n",
    "# 1) You can add examples into the prompt template to improve extraction quality\n",
    "# 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
    "#    about the document from which the text was extracted.)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Only extract relevant information from the text. \"\n",
    "            \"If you do not know the value of an attribute asked to extract\"\n",
    "            \"return null for the attribute's value.\"\n",
    "\n",
    "            \"The text we input is a person's biography. \"\n",
    "            \"You should treat every input text as a separate entity.\"\n",
    "\n",
    "            \"For each person's biography, you should consider:\"\n",
    "            \"If this person has several roles, we should only annotate one.\"\n",
    "            \"If this person is a AI company founder or co-founder, annotate him as a co-founder.\"\n",
    "            \"If this person is a researcher in AI feild, annotate this person as a researcher.\"\n",
    "            \"If you can't find any role, try to conclude the role from the context, if you still can't find any role, please annotate the role as NA.\"\n",
    "\n",
    "            \"For all the biographies with roles as NA, please read the context and try to judge if the biography is from a enterprise account's biography. \"\n",
    "            \"If it is, please annotate the role as 'Y'. If you can't judge, keep the role annotation as 'NA'.\"\n",
    "\n",
    "            \"when you extract company name, please extract the full name of the company and exclude any other punctuation mark such as @.\"\n",
    "            \"If there is no company name, please annotate the company name as NA.\"\n",
    "\n",
    "            \"If this person is related to AI, or anything about AI, please annotate the AI_related as true, otherwise annotate it as false.\"\n",
    "\n",
    "            \"The most important thing is you must extract exactly one combo of information for each input text! not more than one combo of information or less!\"\n",
    "\n",
    "        ),\n",
    "        # Please see the how-to about improving performance with\n",
    "        # reference examples.\n",
    "        # MessagesPlaceholder('examples'),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about people.\"\"\"\n",
    "\n",
    "    # Creates a model so that we can extract multiple entities.\n",
    "    people: List[Person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Dict, List, TypedDict\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "\n",
    "class Example(TypedDict):\n",
    "    \"\"\"A representation of an example consisting of text input and expected tool calls.\n",
    "\n",
    "    For extraction, the tool calls are represented as instances of pydantic model.\n",
    "    \"\"\"\n",
    "\n",
    "    input: str  # This is the example text\n",
    "    tool_calls: List[BaseModel]  # Instances of pydantic model that should be extracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_example_to_messages(example: Example) -> List[BaseMessage]:\n",
    "    \"\"\"Convert an example into a list of messages that can be fed into an LLM.\n",
    "\n",
    "    This code is an adapter that converts our example to a list of messages\n",
    "    that can be fed into a chat model.\n",
    "\n",
    "    The list of messages per example corresponds to:\n",
    "\n",
    "    1) HumanMessage: contains the content from which content should be extracted.\n",
    "    2) AIMessage: contains the extracted information from the model\n",
    "    3) ToolMessage: contains confirmation to the model that the model requested a tool correctly.\n",
    "\n",
    "    The ToolMessage is required because some of the chat models are hyper-optimized for agents\n",
    "    rather than for an extraction use case.\n",
    "    \"\"\"\n",
    "    messages: List[BaseMessage] = [HumanMessage(content=example[\"input\"])]\n",
    "    openai_tool_calls = []\n",
    "    for tool_call in example[\"tool_calls\"]:\n",
    "        openai_tool_calls.append(\n",
    "            {\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    # The name of the function right now corresponds\n",
    "                    # to the name of the pydantic model\n",
    "                    # This is implicit in the API right now,\n",
    "                    # and will be improved over time.\n",
    "                    \"name\": tool_call.__class__.__name__,\n",
    "                    \"arguments\": tool_call.json(),\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "    messages.append(\n",
    "        AIMessage(content=\"\", additional_kwargs={\"tool_calls\": openai_tool_calls})\n",
    "    )\n",
    "    tool_outputs = example.get(\"tool_outputs\") or [\n",
    "        \"You have correctly called this tool.\"\n",
    "    ] * len(openai_tool_calls)\n",
    "    for output, tool_call in zip(tool_outputs, openai_tool_calls):\n",
    "        messages.append(ToolMessage(content=output, tool_call_id=tool_call[\"id\"]))\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    (\n",
    "        \"Research Scientist at Google DeepMind. I tweet about deep learning (research + software), music, generative models (personal account).\",\n",
    "        Person(role=\"Research Scientist\", company=\"Google DeepMind\", interest=\"deep learning, music, and generative models\", ai_related=True),\n",
    "    ),\n",
    "    (\n",
    "        \"I make videos.\\nSkill &gt; Destiny.\\nvi / vim\",\n",
    "        Person(role=None, company=None, interest=None, ai_related=False),\n",
    "    ),\n",
    "    (\n",
    "        \"ML Researcher, co-leading Superalignment @OpenAI. Optimizing for a post-AGI future where humanity flourishes.\",\n",
    "        Person(role=\"ML Researcher\", company=\"OpenAI\", interest=\"AGI\", ai_related=True),\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "messages = []\n",
    "\n",
    "for text, tool_call in examples:\n",
    "    messages.extend(\n",
    "        tool_example_to_messages({\"input\": text, \"tool_calls\": [tool_call]})\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name = 'gpt-4-turbo-preview',\n",
    "    temperature = 0,\n",
    "    openai_api_key = OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TYS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\beta_decorator.py:87: LangChainBetaWarning: The function `with_structured_output` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "runnable = prompt | llm.with_structured_output(\n",
    "    schema=Person,\n",
    "    method=\"function_calling\",\n",
    "    include_raw=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to remove illegal XML characters to every string in the DataFrame\n",
    "# and save directly to an Excel file without the intermediate cleaning step.\n",
    "def clean_and_save_dataset(dataframe):\n",
    "    # Define the function to remove illegal XML characters\n",
    "    def remove_illegal_xml_characters(s):\n",
    "        if isinstance(s, str):\n",
    "            return ''.join(char for char in s if ord(char) >= 32 or char in '\\t\\n\\r')\n",
    "        else:\n",
    "            return s\n",
    "    \n",
    "    # Apply the cleaning function across the DataFrame\n",
    "    cleaned_df = dataframe.applymap(remove_illegal_xml_characters)\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = load_data('twitter1.csv')\n",
    "# Drop NaN values from the 'bio' column\n",
    "df_new = df_new.dropna(subset=['bio'])\n",
    "# Sort the DataFrame by 'tweetsCount' in descending order\n",
    "#df_new = df_new.sort_values(by='followersCount', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intermediate = pd.DataFrame()\n",
    "# Loop through each row in the DataFrame\n",
    "for index, row in df_new.iterrows():\n",
    "    # Add 5 to the followers count\n",
    "    text = row['bio']\n",
    "    extracted_info = runnable.invoke({\"text\": text, \"examples\": messages})\n",
    "    bio_data = {\"role\": extracted_info.role, \"company\": extracted_info.company, \"ai_related\": extracted_info.ai_related,\"row_id\":row['row_id']}\n",
    "    bio_df_new = pd.DataFrame(bio_data, index=[0])\n",
    "    # extracted_info_list = pd.concat([extracted_info_list, bio_df_new])\n",
    "    print(bio_df_new.shape[0])\n",
    "    df_intermediate = pd.concat([df_intermediate, bio_df_new])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(668, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_intermediate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>company</th>\n",
       "      <th>ai_related</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>Coursera</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Policy research</td>\n",
       "      <td>openai</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>co-founder</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chief Scientist</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VP of Research &amp; Deep Learning Lead</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>co-chair</td>\n",
       "      <td>AnthropicAI</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>researcher</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>researcher</td>\n",
       "      <td>openminedorg</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PC</td>\n",
       "      <td>nyuniversity</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Professor</td>\n",
       "      <td>CMU</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Director</td>\n",
       "      <td>Stanford AI Lab</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>co-founder</td>\n",
       "      <td>RekaAILabs</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>GoogleDeepMind</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>researcher</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Principal Scientist</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>researcher</td>\n",
       "      <td>FAIR</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Research Scientist</td>\n",
       "      <td>GoogleAI</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Principal Scientist</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>writer</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minister of State for Digital Economy, A.I. an...</td>\n",
       "      <td>NA</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>President</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US Correspondent</td>\n",
       "      <td>SkyNews</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Venture Capital Investor</td>\n",
       "      <td>Blitzscaling Ventures</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>co-founder</td>\n",
       "      <td>Bellingcat</td>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Foreign Correspondent</td>\n",
       "      <td>Channel4News</td>\n",
       "      <td>False</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>physics-astronomy.com</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deputy Secretary-General</td>\n",
       "      <td>UN</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>founder</td>\n",
       "      <td>UniOfOxford</td>\n",
       "      <td>False</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>BBCHARDtalk</td>\n",
       "      <td>False</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anchor</td>\n",
       "      <td>CNN</td>\n",
       "      <td>False</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prime Minister</td>\n",
       "      <td>State of Israel</td>\n",
       "      <td>False</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>consultant</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Entrepreneur &amp; Investor</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>co-founder</td>\n",
       "      <td>therundownai</td>\n",
       "      <td>True</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>SemiAnalysis</td>\n",
       "      <td>True</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comms Manager</td>\n",
       "      <td>eurojewcong</td>\n",
       "      <td>False</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>President and CEO</td>\n",
       "      <td>RAND Corporation</td>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>strategist</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>True</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>researcher</td>\n",
       "      <td>NA</td>\n",
       "      <td>True</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>GoogleDeepMind</td>\n",
       "      <td>True</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Analyst</td>\n",
       "      <td>Eurasia Group</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>False</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>co-founder</td>\n",
       "      <td>LoreEACC</td>\n",
       "      <td>False</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                role                company  \\\n",
       "0                                                 NA                     NA   \n",
       "0                                                  Y               Coursera   \n",
       "0                                                  Y                     NA   \n",
       "0                                                 NA                     NA   \n",
       "0                                    Policy research                 openai   \n",
       "0                                         co-founder                 OpenAI   \n",
       "0                                    Chief Scientist        Google DeepMind   \n",
       "0                VP of Research & Deep Learning Lead        Google DeepMind   \n",
       "0                                           co-chair            AnthropicAI   \n",
       "0                                         researcher        Google DeepMind   \n",
       "0                                         researcher           openminedorg   \n",
       "0                                                 PC           nyuniversity   \n",
       "0                                                 NA                     NA   \n",
       "0                                                 NA                     NA   \n",
       "0                                          Professor                    CMU   \n",
       "0                                           Director        Stanford AI Lab   \n",
       "0                                         co-founder             RekaAILabs   \n",
       "0                                 Research Scientist         GoogleDeepMind   \n",
       "0                                         researcher                 OpenAI   \n",
       "0                                Principal Scientist        Google DeepMind   \n",
       "0                                         researcher                   FAIR   \n",
       "0                          Senior Research Scientist               GoogleAI   \n",
       "0                                Principal Scientist        Google DeepMind   \n",
       "0                                                 NA                     NA   \n",
       "0                                                 NA                     NA   \n",
       "0                                             writer                     NA   \n",
       "0  Minister of State for Digital Economy, A.I. an...                     NA   \n",
       "0                                                 NA                     NA   \n",
       "0                                          President                     NA   \n",
       "0                                   US Correspondent                SkyNews   \n",
       "0                           Venture Capital Investor  Blitzscaling Ventures   \n",
       "0                                         co-founder             Bellingcat   \n",
       "0                              Foreign Correspondent           Channel4News   \n",
       "0                                                 NA  physics-astronomy.com   \n",
       "0                           Deputy Secretary-General                     UN   \n",
       "0                                                 NA                     NA   \n",
       "0                                            founder            UniOfOxford   \n",
       "0                                                 NA            BBCHARDtalk   \n",
       "0                                                 NA                     NA   \n",
       "0                                             Anchor                    CNN   \n",
       "0                                                 NA                     NA   \n",
       "0                                     Prime Minister        State of Israel   \n",
       "0                                                 NA                     NA   \n",
       "0                                         consultant                     NA   \n",
       "0                            Entrepreneur & Investor                     NA   \n",
       "0                                         co-founder           therundownai   \n",
       "0                                                 NA           SemiAnalysis   \n",
       "0                                      Comms Manager            eurojewcong   \n",
       "0                                  President and CEO       RAND Corporation   \n",
       "0                                         strategist              Microsoft   \n",
       "0                                         researcher                     NA   \n",
       "0                                 Research Scientist         GoogleDeepMind   \n",
       "0                                     Senior Analyst          Eurasia Group   \n",
       "0                                                 NA                     NA   \n",
       "0                                                 NA                     NA   \n",
       "0                                                 NA                     NA   \n",
       "0                                                 NA                     NA   \n",
       "0                                                 NA                     NA   \n",
       "0                                                 NA                     NA   \n",
       "0                                         co-founder               LoreEACC   \n",
       "\n",
       "   ai_related  row_id  \n",
       "0        True       1  \n",
       "0       False       3  \n",
       "0       False       4  \n",
       "0       False       5  \n",
       "0        True       6  \n",
       "0        True       7  \n",
       "0        True       8  \n",
       "0        True       9  \n",
       "0        True      10  \n",
       "0        True      11  \n",
       "0        True      12  \n",
       "0        True      13  \n",
       "0       False      14  \n",
       "0       False      15  \n",
       "0        True      16  \n",
       "0        True      17  \n",
       "0        True      18  \n",
       "0        True      19  \n",
       "0        True      20  \n",
       "0        True      21  \n",
       "0        True      22  \n",
       "0        True      23  \n",
       "0        True      24  \n",
       "0       False      25  \n",
       "0       False      26  \n",
       "0       False      27  \n",
       "0        True      28  \n",
       "0       False      29  \n",
       "0       False      30  \n",
       "0       False      31  \n",
       "0       False      32  \n",
       "0       False      33  \n",
       "0       False      34  \n",
       "0       False      35  \n",
       "0       False      36  \n",
       "0       False      37  \n",
       "0       False      38  \n",
       "0       False      39  \n",
       "0       False      40  \n",
       "0       False      41  \n",
       "0       False      42  \n",
       "0       False      43  \n",
       "0       False      44  \n",
       "0       False      45  \n",
       "0       False      46  \n",
       "0        True      47  \n",
       "0        True      48  \n",
       "0       False      49  \n",
       "0       False      50  \n",
       "0        True      51  \n",
       "0        True      52  \n",
       "0        True      53  \n",
       "0       False      54  \n",
       "0       False      55  \n",
       "0       False      57  \n",
       "0       False      58  \n",
       "0       False      59  \n",
       "0       False      60  \n",
       "0       False      61  \n",
       "0       False      62  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_intermediate.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(df_intermediate, 'bio_intermediate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a left join on 'row_id'\n",
    "combined_df = df_new.merge(df_intermediate, on='row_id', how='left', suffixes=('', '_modified'))\n",
    "save_result(combined_df, 'twitter1_extracted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new = load_data('twitter2.csv')\n",
    "df_new = load_excel('twitter_2.xlsx')\n",
    "# Drop NaN values from the 'bio' column\n",
    "df_new = df_new.dropna(subset=['bio'])\n",
    "# Sort the DataFrame by 'tweetsCount' in descending order\n",
    "#df_new = df_new.sort_values(by='followersCount', ascending=False)\n",
    "df_new = clean_and_save_dataset(df_new)\n",
    "\n",
    "df_intermediate = pd.DataFrame()\n",
    "# Loop through each row in the DataFrame\n",
    "for index, row in df_new.iterrows():\n",
    "    # Add 5 to the followers count\n",
    "    text = row['bio']\n",
    "    extracted_info = runnable.invoke({\"text\": text, \"examples\": messages})\n",
    "    bio_data = {\"role\": extracted_info.role, \"company\": extracted_info.company, \"ai_related\": extracted_info.ai_related,\"row_id\":row['row_id']}\n",
    "    bio_df_new = pd.DataFrame(bio_data, index=[0])\n",
    "    # extracted_info_list = pd.concat([extracted_info_list, bio_df_new])\n",
    "    #print(bio_df_new.shape[0])\n",
    "    df_intermediate = pd.concat([df_intermediate, bio_df_new])\n",
    "# Perform a left join on 'row_id'\n",
    "combined_df = df_new.merge(df_intermediate, on='row_id', how='left', suffixes=('', '_modified'))\n",
    "save_excel(combined_df, 'twitter2_extracted.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new = load_data('twitter2.csv')\n",
    "df_new = load_excel('twitter_3.xlsx')\n",
    "# Drop NaN values from the 'bio' column\n",
    "df_new = df_new.dropna(subset=['bio'])\n",
    "# Sort the DataFrame by 'tweetsCount' in descending order\n",
    "#df_new = df_new.sort_values(by='followersCount', ascending=False)\n",
    "df_new = clean_and_save_dataset(df_new)\n",
    "\n",
    "df_intermediate = pd.DataFrame()\n",
    "# Loop through each row in the DataFrame\n",
    "for index, row in df_new.iterrows():\n",
    "    # Add 5 to the followers count\n",
    "    text = row['bio']\n",
    "    extracted_info = runnable.invoke({\"text\": text, \"examples\": messages})\n",
    "    bio_data = {\"role\": extracted_info.role, \"company\": extracted_info.company, \"ai_related\": extracted_info.ai_related,\"row_id\":row['row_id']}\n",
    "    bio_df_new = pd.DataFrame(bio_data, index=[0])\n",
    "    # extracted_info_list = pd.concat([extracted_info_list, bio_df_new])\n",
    "    #print(bio_df_new.shape[0])\n",
    "    df_intermediate = pd.concat([df_intermediate, bio_df_new])\n",
    "# Perform a left join on 'row_id'\n",
    "combined_df = df_new.merge(df_intermediate, on='row_id', how='left', suffixes=('', '_modified'))\n",
    "save_excel(combined_df, 'twitter3_extracted.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new = load_data('twitter2.csv')\n",
    "df_new = load_excel('twitter_4.xlsx')\n",
    "# Drop NaN values from the 'bio' column\n",
    "df_new = df_new.dropna(subset=['bio'])\n",
    "# Sort the DataFrame by 'tweetsCount' in descending order\n",
    "#df_new = df_new.sort_values(by='followersCount', ascending=False)\n",
    "df_new = clean_and_save_dataset(df_new)\n",
    "\n",
    "df_intermediate = pd.DataFrame()\n",
    "# Loop through each row in the DataFrame\n",
    "for index, row in df_new.iterrows():\n",
    "    # Add 5 to the followers count\n",
    "    text = row['bio']\n",
    "    extracted_info = runnable.invoke({\"text\": text, \"examples\": messages})\n",
    "    bio_data = {\"role\": extracted_info.role, \"company\": extracted_info.company, \"ai_related\": extracted_info.ai_related,\"row_id\":row['row_id']}\n",
    "    bio_df_new = pd.DataFrame(bio_data, index=[0])\n",
    "    # extracted_info_list = pd.concat([extracted_info_list, bio_df_new])\n",
    "    #print(bio_df_new.shape[0])\n",
    "    df_intermediate = pd.concat([df_intermediate, bio_df_new])\n",
    "# Perform a left join on 'row_id'\n",
    "combined_df = df_new.merge(df_intermediate, on='row_id', how='left', suffixes=('', '_modified'))\n",
    "save_excel(combined_df, 'twitter4_extracted.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
